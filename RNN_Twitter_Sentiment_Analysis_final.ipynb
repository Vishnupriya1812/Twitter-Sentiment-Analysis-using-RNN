{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov4n2hl42hmZ"
      },
      "source": [
        "# Twitter US Airline Sentiment Analysis with an RNN\n",
        "### Analyze how travelers in February 2015 expressed their feelings on Twitter\n",
        "\n",
        "In this notebook, we implement a recurrent neural network to analyze how travelers in February 2015 expressed their feelings on Twitter. Using an RNN rather than a strictly feedforward network is more accurate since we can include information about the *sequence* of words. \n",
        "\n",
        "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
        "\n",
        "In this notebook, our goal is to identify whether a tweet is negative or non-negative (positive or neutral)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ainG4iY52hmf"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "The architecture for this network is shown below.\n",
        "\n",
        "<img src=\"assets/network_diagram.png\" width=40%>\n",
        "\n",
        ">**First, we'll pass in words to an embedding layer.** We need an embedding layer because we have tens of thousands of words, so we'll need a more efficient representation for our input data than one-hot encoded vectors. \n",
        "\n",
        ">**After input words are passed to an embedding layer, the new embeddings will be passed to LSTM cells.** The LSTM cells will add *recurrent* connections to the network and give us the ability to include information about the *sequence* of words.\n",
        "\n",
        ">**Finally, the LSTM outputs will go to a sigmoid output layer.** We're using a sigmoid function because we have two classes (0 is negative and 1 is non-negative) and a sigmoid will output predicted sentiment values between 0-1. \n",
        "\n",
        "We don't care about the sigmoid outputs except for the **very last one**; we can ignore the rest. We'll calculate the loss by comparing the output at the last time step and the training label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihHLvFQ82hmg"
      },
      "source": [
        "---\n",
        "## Load in and visualize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "coJr0ijw2hmh",
        "outputId": "f3e2a64b-b7bf-4993-ef52-d4349ae131f3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
              "0  570306133677760513           neutral                        1.0000   \n",
              "1  570301130888122368          positive                        0.3486   \n",
              "2  570301083672813571           neutral                        0.6837   \n",
              "3  570301031407624196          negative                        1.0000   \n",
              "4  570300817074462722          negative                        1.0000   \n",
              "\n",
              "  negativereason  negativereason_confidence         airline  \\\n",
              "0            NaN                        NaN  Virgin America   \n",
              "1            NaN                     0.0000  Virgin America   \n",
              "2            NaN                        NaN  Virgin America   \n",
              "3     Bad Flight                     0.7033  Virgin America   \n",
              "4     Can't Tell                     1.0000  Virgin America   \n",
              "\n",
              "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
              "0                    NaN     cairdin                 NaN              0   \n",
              "1                    NaN    jnardino                 NaN              0   \n",
              "2                    NaN  yvonnalynn                 NaN              0   \n",
              "3                    NaN    jnardino                 NaN              0   \n",
              "4                    NaN    jnardino                 NaN              0   \n",
              "\n",
              "                                                text tweet_coord  \\\n",
              "0                @VirginAmerica What @dhepburn said.         NaN   \n",
              "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
              "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
              "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
              "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
              "\n",
              "               tweet_created tweet_location               user_timezone  \n",
              "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
              "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
              "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
              "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
              "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fed0e85-4be6-452a-8ffa-49fadc84b0b9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fed0e85-4be6-452a-8ffa-49fadc84b0b9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fed0e85-4be6-452a-8ffa-49fadc84b0b9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fed0e85-4be6-452a-8ffa-49fadc84b0b9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/Tweets.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DA56T0f2hmk"
      },
      "source": [
        "We only use the data in the `text` and `airline_sentiment` column. we also only use 14000 data rows of the total 14640 data rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "m7DnYLyQ2hmk"
      },
      "outputs": [],
      "source": [
        "reviews = np.array(data['text'])[:14000]\n",
        "labels = np.array(data['airline_sentiment'])[:14000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3UETO7Vd2hml",
        "outputId": "ee5c34cf-dad7-4475-f818-442f2922477b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'@AmericanAir we have 8 ppl so we need 2 know how many seats are on the next flight. Plz put us on standby for 4 people on the next flight?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data['text'].loc[14639]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kuISPqro2hml",
        "outputId": "c27ef3b8-4a8c-4881-d42b-e72a4148c846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data['airline_sentiment'].loc[14639]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hbQUCYS2hml"
      },
      "source": [
        "Let's see the distribution of the airline sentiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic8CM3rK2hmm",
        "outputId": "57e8f33b-8b85-4012-fab4-44677b860417"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'neutral': 3017, 'positive': 2304, 'negative': 8679})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJXoZZiH2hmm"
      },
      "source": [
        "---\n",
        "## Data pre-processing\n",
        "The first step when building a neural network model is getting the data into the proper form to feed into the network. Since we're using embedding layers, we'll need to encode each word with an integer. We'll also want to clean it up a bit.\n",
        "\n",
        "Here are the processing steps, we'll want to take:\n",
        ">* We'll want to get rid of periods and extraneous punctuation.\n",
        "* We'll want to remove web address, twitter id, and digit. \n",
        "\n",
        "First, let's remove all punctuation. Then get all the text without the newlines and split it into individual words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "wjtzO_yd2hmm"
      },
      "outputs": [],
      "source": [
        "punctuation = '!\"#$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
        "\n",
        "# get rid of punctuation\n",
        "all_reviews = 'separator'.join(reviews)\n",
        "all_reviews = all_reviews.lower()\n",
        "all_text = ''.join([c for c in all_reviews if c not in punctuation])\n",
        "\n",
        "# split by new lines and spaces\n",
        "reviews_split = all_text.split('separator')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "# create a list of words\n",
        "words = all_text.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHevVSNt2hmm"
      },
      "source": [
        "Then, we remove web address, twitter id, and digit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "ohFDAQag2hmn"
      },
      "outputs": [],
      "source": [
        "# get rid of web address, twitter id, and digit\n",
        "new_reviews = []\n",
        "for review in reviews_split:\n",
        "    review = review.split()\n",
        "    new_text = []\n",
        "    for word in review:\n",
        "        if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n",
        "            new_text.append(word)\n",
        "    new_reviews.append(new_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6pUH-5_2hmn"
      },
      "source": [
        "### Encoding the words\n",
        "The embedding lookup requires that we pass in integers to our network. The easiest way to do this is to create dictionaries that map the words in the vocabulary to integers. Then, we can convert each of our reviews into integers so they can be passed into the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eeWroxg12hmn"
      },
      "outputs": [],
      "source": [
        "## Build a dictionary that maps words to integers\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "vocab_to_int = {word: ii for ii, word in enumerate(vocab, 1)}\n",
        "\n",
        "## use the dict to tokenize each review in reviews_split\n",
        "## store the tokenized reviews in reviews_ints\n",
        "reviews_ints = []\n",
        "for review in new_reviews:\n",
        "    reviews_ints.append([vocab_to_int[word] for word in review])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hvo39O1L2hmo"
      },
      "source": [
        "Let's print out the number of unique words in the vocabulary and the contents of the first, tokenized review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf4GCyRd2hmo",
        "outputId": "efe50df6-79ea-428a-c5ec-0fd22e3a8052"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words:  16727\n",
            "\n",
            "Tokenized review: \n",
            " [[57, 213]]\n"
          ]
        }
      ],
      "source": [
        "# stats about vocabulary\n",
        "print('Unique words: ', len((vocab_to_int)))  # should ~ 74000+\n",
        "print()\n",
        "\n",
        "# print tokens in first review\n",
        "print('Tokenized review: \\n', reviews_ints[:1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.under_sampling import TomekLinks\n",
        "\n",
        "tomek = TomekLinks(sampling_strategy='auto')\n",
        "tomek.fit(reviews_ints,data['airline_sentiment'])\n",
        "X_tomek_sampled,y_tomek_sampled = tomek.fit_resample(reviews_ints,data['airline_sentiment'])"
      ],
      "metadata": {
        "id": "AzKrVXRQ8cmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12fSYokM2hmo"
      },
      "source": [
        "### Encoding the labels\n",
        "As mentioned before, our goal is to identify whether a tweet is negative or non-negative (positive or neutral). Our labels are \"positive\", \"negative\", or \"neutral. To use these labels in our network, we need to convert them to 0 and 1. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "VjvxCmNE2hmq"
      },
      "outputs": [],
      "source": [
        "# 1=positive, 1=neutral, 0=negative label conversion\n",
        "encoded_labels = []\n",
        "for label in labels:\n",
        "    if label == 'neutral':\n",
        "        encoded_labels.append(1)\n",
        "    elif label == 'negative':\n",
        "        encoded_labels.append(0)\n",
        "    else:\n",
        "        encoded_labels.append(1)\n",
        "\n",
        "encoded_labels = np.asarray(encoded_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdsEl9Tc2hmr"
      },
      "source": [
        "### Padding sequences\n",
        "To deal with both short and very long reviews, we'll pad or truncate all our reviews to a specific length. For reviews shorter than some `seq_length`, we'll pad with 0s. For reviews longer than `seq_length`, we can truncate them to the first `seq_length` words. A good `seq_length`, in this case, is 30, because the maximum review length from the data is 32.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "b2DQSzzJ2hmr"
      },
      "outputs": [],
      "source": [
        "def pad_features(reviews_ints, seq_length):\n",
        "    ''' Return features of review_ints, where each review is padded with 0's \n",
        "        or truncated to the input seq_length.\n",
        "    '''\n",
        "    \n",
        "    # getting the correct rows x cols shape\n",
        "    features = np.zeros((len(reviews_ints), seq_length), dtype=int)\n",
        "\n",
        "    # for each review, I grab that review and \n",
        "    for i, row in enumerate(reviews_ints):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "    \n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlbWq-HN2hms",
        "outputId": "ab78707f-cb36-4a43-883c-0824a92c5d69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 446]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0]]\n"
          ]
        }
      ],
      "source": [
        "# Test implementation!\n",
        "\n",
        "seq_length = 30\n",
        "\n",
        "features = pad_features(reviews_ints, seq_length=seq_length)\n",
        "\n",
        "## test statements \n",
        "assert len(features)==len(reviews_ints), \"The features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "# print first 10 values of the first 30 batches \n",
        "print(features[:10,:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g46laBlZ2hms"
      },
      "source": [
        "---\n",
        "## Training, validation, and test\n",
        "With our data in nice shape, we'll split it into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvVe6Q5e2hms",
        "outputId": "8674eb51-1a50-479c-b658-9a6b6679cb79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(11200, 30) \n",
            "Validation set: \t(1400, 30) \n",
            "Test set: \t\t(1400, 30)\n"
          ]
        }
      ],
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "## split data into training, validation, and test data (features and labels, x and y)\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "## print out the shapes of the resultant feature data\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWz45KlKbrGF",
        "outputId": "ad50bbd9-a910-4e9c-ebea-23a23901e165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycaret\n",
            "  Downloading pycaret-3.0.0-py3-none-any.whl (481 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 KB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy<2.0.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.10.1)\n",
            "Collecting sktime>=0.16.1\n",
            "  Downloading sktime-0.17.0-py3-none-any.whl (16.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.9.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (5.9.4)\n",
            "Collecting pyod>=1.0.8\n",
            "  Downloading pyod-1.0.9.tar.gz (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.0/150.0 KB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: yellowbrick>=1.4 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.5)\n",
            "Requirement already satisfied: lightgbm>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.3.5)\n",
            "Collecting kaleido>=0.2.1\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.2.2)\n",
            "Collecting category-encoders>=2.4.0\n",
            "  Downloading category_encoders-2.6.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (7.34.0)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting plotly-resampler>=0.8.3.1\n",
            "  Downloading plotly_resampler-0.8.3.2.tar.gz (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting joblib>=1.2.0\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.7.1)\n",
            "Requirement already satisfied: numba>=0.55.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.56.4)\n",
            "Requirement already satisfied: jinja2>=1.2 in /usr/local/lib/python3.9/dist-packages (from pycaret) (3.1.2)\n",
            "Collecting wurlitzer\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting deprecation>=2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy<1.25,>=1.21 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.9/dist-packages (from pycaret) (2.2.1)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (2.27.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.12.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (6.1.0)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (4.65.0)\n",
            "Collecting scikit-plot>=0.3.7\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.13.5)\n",
            "Requirement already satisfied: pandas<1.6.0,>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (1.4.4)\n",
            "Requirement already satisfied: markupsafe>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (2.1.2)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (5.13.1)\n",
            "Collecting schemdraw>=0.14\n",
            "  Downloading schemdraw-0.16-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.8/105.8 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pycaret) (5.8.0)\n",
            "Collecting pmdarima!=1.8.1,<3.0.0,>=1.8.0\n",
            "  Downloading pmdarima-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: imbalanced-learn>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from pycaret) (0.10.1)\n",
            "Collecting tbats>=1.1.0\n",
            "  Downloading tbats-1.1.2-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 KB\u001b[0m \u001b[31m145.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: ipywidgets>=7.6.5 in /usr/local/lib/python3.9/dist-packages (from pycaret) (7.7.1)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from category-encoders>=2.4.0->pycaret) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from deprecation>=2.1.0->pycaret) (23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced-learn>=0.8.1->pycaret) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.12.0->pycaret) (3.15.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (0.2.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (0.7.5)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (0.1.6)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (4.4.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (3.0.38)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (67.6.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=5.5.0->pycaret) (2.14.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.6.5->pycaret) (5.5.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.0.7)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.6.5->pycaret) (0.2.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets>=7.6.5->pycaret) (3.6.4)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from lightgbm>=3.0.0->pycaret) (0.40.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (1.0.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (8.4.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.3.0->pycaret) (4.39.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat>=4.2.0->pycaret) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat>=4.2.0->pycaret) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.9/dist-packages (from nbformat>=4.2.0->pycaret) (5.3.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.55.0->pycaret) (0.39.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<1.6.0,>=1.3.0->pycaret) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=5.0.0->pycaret) (8.2.2)\n",
            "Collecting jupyter-dash>=0.4.2\n",
            "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
            "Collecting orjson<4.0.0,>=3.8.0\n",
            "  Downloading orjson-3.8.9-cp39-cp39-manylinux_2_28_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.1/144.1 KB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dash<3.0.0,>=2.2.0\n",
            "  Downloading dash-2.9.2-py3-none-any.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trace-updater>=0.0.8\n",
            "  Downloading trace_updater-0.0.9-py3-none-any.whl (185 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.1/185.1 KB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (1.26.15)\n",
            "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in /usr/local/lib/python3.9/dist-packages (from pmdarima!=1.8.1,<3.0.0,>=1.8.0->pycaret) (0.29.34)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from pyod>=1.0.8->pycaret) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.1->pycaret) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.1->pycaret) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.27.1->pycaret) (3.4)\n",
            "Collecting deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from dash<3.0.0,>=2.2.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.3)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from deprecated>=1.2.13->sktime>=0.16.1->pycaret) (1.14.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets>=7.6.5->pycaret) (6.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=5.5.0->pycaret) (0.8.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (0.19.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret) (22.2.0)\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Collecting ansi2html\n",
            "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.9/dist-packages (from jupyter-dash>=0.4.2->plotly-resampler>=0.8.3.1->pycaret) (1.5.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=5.5.0->pycaret) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->pycaret) (0.2.6)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.4.8)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core->nbformat>=4.2.0->pycaret) (3.2.0)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler>=0.8.3.1->pycaret) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler>=0.8.3.1->pycaret) (8.1.3)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.9/dist-packages (from Flask>=1.0.4->dash<3.0.0,>=2.2.0->plotly-resampler>=0.8.3.1->pycaret) (2.2.3)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.5.4)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (23.2.1)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.17.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.3.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (21.2.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.9.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (6.0.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.2.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.2.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.4)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.8.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (4.11.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (1.15.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (0.5.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets>=7.6.5->pycaret) (2.21)\n",
            "Building wheels for collected packages: plotly-resampler, pyod\n",
            "  Building wheel for plotly-resampler (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plotly-resampler: filename=plotly_resampler-0.8.3.2-cp39-cp39-manylinux_2_31_x86_64.whl size=75056 sha256=e7acd99c06393e31f92b6e151d0e919ed8e77e8b8c30bf2466338d80a7db1b33\n",
            "  Stored in directory: /root/.cache/pip/wheels/9e/36/06/4c11e300918011376af149098621ec7ebe06d8256566d43d51\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-1.0.9-py3-none-any.whl size=184112 sha256=24a6949fd6399e592ad8a49eb0e06d9b662b143a18b27b1712a3213dc042ab43\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/9c/b8/9759d7cc64a1e01bb9872ade80cb7db445ccf506e083325106\n",
            "Successfully built plotly-resampler pyod\n",
            "Installing collected packages: trace-updater, kaleido, dash-table, dash-html-components, dash-core-components, xxhash, wurlitzer, schemdraw, retrying, orjson, joblib, jedi, deprecation, deprecated, ansi2html, sktime, scikit-plot, pyod, dash, pmdarima, jupyter-dash, category-encoders, tbats, plotly-resampler, pycaret\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.1.1\n",
            "    Uninstalling joblib-1.1.1:\n",
            "      Successfully uninstalled joblib-1.1.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-profiling 3.2.0 requires joblib~=1.1.0, but you have joblib 1.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ansi2html-1.8.0 category-encoders-2.6.0 dash-2.9.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecated-1.2.13 deprecation-2.1.0 jedi-0.18.2 joblib-1.2.0 jupyter-dash-0.4.2 kaleido-0.2.1 orjson-3.8.9 plotly-resampler-0.8.3.2 pmdarima-2.0.3 pycaret-3.0.0 pyod-1.0.9 retrying-1.3.4 schemdraw-0.16 scikit-plot-0.3.7 sktime-0.17.0 tbats-1.1.2 trace-updater-0.0.9 wurlitzer-3.0.3 xxhash-3.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8Od1b3sxDtG",
        "outputId": "c3ade978-7c7b-4e05-838f-eb8da45b9b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "r8Oc0_6GxJWb",
        "outputId": "deafa330-1b6e-49e4-c828-aa1e2c5d715f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret.classification import *\n",
        "wandb.init(project='dl_package')\n",
        "s = setup(\n",
        "          data,\n",
        "          target = 'airline_sentiment',\n",
        "          ignore_features = ['tweet_ID'],\n",
        "          log_experiment=\"wandb\",\n",
        "          log_plots= True,\n",
        "          log_profile=True,\n",
        "          log_data=True,\n",
        "          experiment_name=\"teststst\"\n",
        "          )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uHlXI0ylbywA",
        "outputId": "c93c5179-7fd4-461f-f94d-608c5183f44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvishnu2002\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.14.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230406_041209-v2ag4esm</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/vishnu2002/dl_package/runs/v2ag4esm' target=\"_blank\">jem-hadar-data-4</a></strong> to <a href='https://wandb.ai/vishnu2002/dl_package' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/vishnu2002/dl_package' target=\"_blank\">https://wandb.ai/vishnu2002/dl_package</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/vishnu2002/dl_package/runs/v2ag4esm' target=\"_blank\">https://wandb.ai/vishnu2002/dl_package/runs/v2ag4esm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f59c9d94f10>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4f15a_row12_col1 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4f15a\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4f15a_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
              "      <th id=\"T_4f15a_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_4f15a_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
              "      <td id=\"T_4f15a_row0_col1\" class=\"data row0 col1\" >7214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_4f15a_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
              "      <td id=\"T_4f15a_row1_col1\" class=\"data row1 col1\" >airline_sentiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_4f15a_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
              "      <td id=\"T_4f15a_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_4f15a_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
              "      <td id=\"T_4f15a_row3_col1\" class=\"data row3 col1\" >negative: 0, neutral: 1, positive: 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_4f15a_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
              "      <td id=\"T_4f15a_row4_col1\" class=\"data row4 col1\" >(14640, 15)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_4f15a_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
              "      <td id=\"T_4f15a_row5_col1\" class=\"data row5 col1\" >(14640, 147)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_4f15a_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
              "      <td id=\"T_4f15a_row6_col1\" class=\"data row6 col1\" >(10248, 147)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_4f15a_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
              "      <td id=\"T_4f15a_row7_col1\" class=\"data row7 col1\" >(4392, 147)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_4f15a_row8_col0\" class=\"data row8 col0\" >Ignore features</td>\n",
              "      <td id=\"T_4f15a_row8_col1\" class=\"data row8 col1\" >1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_4f15a_row9_col0\" class=\"data row9 col0\" >Numeric features</td>\n",
              "      <td id=\"T_4f15a_row9_col1\" class=\"data row9 col1\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_4f15a_row10_col0\" class=\"data row10 col0\" >Categorical features</td>\n",
              "      <td id=\"T_4f15a_row10_col1\" class=\"data row10 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_4f15a_row11_col0\" class=\"data row11 col0\" >Rows with missing values</td>\n",
              "      <td id=\"T_4f15a_row11_col1\" class=\"data row11 col1\" >100.0%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_4f15a_row12_col0\" class=\"data row12 col0\" >Preprocess</td>\n",
              "      <td id=\"T_4f15a_row12_col1\" class=\"data row12 col1\" >True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_4f15a_row13_col0\" class=\"data row13 col0\" >Imputation type</td>\n",
              "      <td id=\"T_4f15a_row13_col1\" class=\"data row13 col1\" >simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_4f15a_row14_col0\" class=\"data row14 col0\" >Numeric imputation</td>\n",
              "      <td id=\"T_4f15a_row14_col1\" class=\"data row14 col1\" >mean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
              "      <td id=\"T_4f15a_row15_col0\" class=\"data row15 col0\" >Categorical imputation</td>\n",
              "      <td id=\"T_4f15a_row15_col1\" class=\"data row15 col1\" >mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
              "      <td id=\"T_4f15a_row16_col0\" class=\"data row16 col0\" >Maximum one-hot encoding</td>\n",
              "      <td id=\"T_4f15a_row16_col1\" class=\"data row16 col1\" >25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
              "      <td id=\"T_4f15a_row17_col0\" class=\"data row17 col0\" >Encoding method</td>\n",
              "      <td id=\"T_4f15a_row17_col1\" class=\"data row17 col1\" >None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
              "      <td id=\"T_4f15a_row18_col0\" class=\"data row18 col0\" >Fold Generator</td>\n",
              "      <td id=\"T_4f15a_row18_col1\" class=\"data row18 col1\" >StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
              "      <td id=\"T_4f15a_row19_col0\" class=\"data row19 col0\" >Fold Number</td>\n",
              "      <td id=\"T_4f15a_row19_col1\" class=\"data row19 col1\" >10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
              "      <td id=\"T_4f15a_row20_col0\" class=\"data row20 col0\" >CPU Jobs</td>\n",
              "      <td id=\"T_4f15a_row20_col1\" class=\"data row20 col1\" >-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
              "      <td id=\"T_4f15a_row21_col0\" class=\"data row21 col0\" >Use GPU</td>\n",
              "      <td id=\"T_4f15a_row21_col1\" class=\"data row21 col1\" >False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
              "      <td id=\"T_4f15a_row22_col0\" class=\"data row22 col0\" >Log Experiment</td>\n",
              "      <td id=\"T_4f15a_row22_col1\" class=\"data row22 col1\" >WandbLogger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
              "      <td id=\"T_4f15a_row23_col0\" class=\"data row23 col0\" >Experiment Name</td>\n",
              "      <td id=\"T_4f15a_row23_col1\" class=\"data row23 col1\" >teststst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4f15a_level0_row24\" class=\"row_heading level0 row24\" >24</th>\n",
              "      <td id=\"T_4f15a_row24_col0\" class=\"data row24 col0\" >USI</td>\n",
              "      <td id=\"T_4f15a_row24_col1\" class=\"data row24 col1\" >5508</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-4448754942ff>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dl_package'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m s = setup(\n\u001b[0m\u001b[1;32m      4\u001b[0m           \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'airline_sentiment'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pycaret/classification/functional.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, group_names, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, fix_imbalance, fix_imbalance_method, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_EXPERIMENT_CLASS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0mset_current_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m     return exp.setup(\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m         \u001b[0mdata_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pycaret/classification/oop.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, data, data_func, target, index, train_size, test_data, ordinal_features, numeric_features, categorical_features, date_features, text_features, ignore_features, keep_features, preprocess, create_date_columns, imputation_type, numeric_imputation, categorical_imputation, iterative_imputation_iters, numeric_iterative_imputer, categorical_iterative_imputer, text_features_method, max_encoding_ohe, encoding_method, rare_to_value, rare_value, polynomial_features, polynomial_degree, low_variance_threshold, group_features, group_names, drop_groups, remove_multicollinearity, multicollinearity_threshold, bin_numeric_features, remove_outliers, outliers_method, outliers_threshold, fix_imbalance, fix_imbalance_method, transformation, transformation_method, normalize, normalize_method, pca, pca_method, pca_components, feature_selection, feature_selection_method, feature_selection_estimator, n_features_to_select, custom_pipeline, custom_pipeline_position, data_split_shuffle, data_split_stratify, fold_strategy, fold, fold_shuffle, fold_groups, n_jobs, use_gpu, html, session_id, system_log, log_experiment, experiment_name, experiment_custom_tags, log_plots, log_profile, log_data, engine, verbose, memory, profile, profile_kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mruntime_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         self._set_up_logging(\n\u001b[0m\u001b[1;32m   1026\u001b[0m             \u001b[0mruntime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0mlog_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py\u001b[0m in \u001b[0;36m_set_up_logging\u001b[0;34m(self, runtime, log_data, log_profile, experiment_custom_tags)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_param\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             self.logging_param.log_experiment(\n\u001b[0m\u001b[1;32m    265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mlog_profile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pycaret/loggers/dashboard_logger.py\u001b[0m in \u001b[0;36mlog_experiment\u001b[0;34m(self, experiment, log_profile, log_data, experiment_custom_tags, runtime)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlog_profile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mprofile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data Profile.html\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m                 \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m                 [\n\u001b[1;32m    240\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_profile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ClassificationExperiment' object has no attribute 'report'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3dnTTq62hmt"
      },
      "source": [
        "### DataLoaders and Batching\n",
        "After creating training, test, and validation data, we can create DataLoaders for this data by following two steps:\n",
        "1. Create a known format for accessing our data, using [TensorDataset](https://pytorch.org/docs/stable/data.html#) which takes in an input set of data and a target set of data with the same first dimension, and creates a dataset.\n",
        "2. Create DataLoaders and batch our training, validation, and test Tensor datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "F_RQxBfN2hmt"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# create Tensor datasets\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "# dataloaders\n",
        "batch_size = 50\n",
        "\n",
        "# make sure the SHUFFLE the training data\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sci1Gi7O2hmt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c9e133-b64d-4750-e80b-acc66f945c99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 30])\n",
            "Sample input: \n",
            " tensor([[   0,    0,    0,  ...,   11, 3421,   97],\n",
            "        [   0,    0,    0,  ...,   34,  156,    5],\n",
            "        [   0,    0,    0,  ...,  304,   68,  118],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,   54,   30,   20],\n",
            "        [   0,    0,    0,  ...,   30,  508, 8074],\n",
            "        [   0,    0,    0,  ...,  298, 1904, 7092]])\n",
            "\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label: \n",
            " tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0])\n"
          ]
        }
      ],
      "source": [
        "# obtain one batch of training data\n",
        "dataiter = iter(train_loader)\n",
        "dataiter = next(dataiter)\n",
        "sample_x, sample_y = dataiter\n",
        "\n",
        "print('Sample input size: ', sample_x.size()) # batch_size, seq_length\n",
        "print('Sample input: \\n', sample_x)\n",
        "print()\n",
        "print('Sample label size: ', sample_y.size()) # batch_size\n",
        "print('Sample label: \\n', sample_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "381Re1gm2hmt"
      },
      "source": [
        "---\n",
        "## Sentiment Network with PyTorch\n",
        "Below is where we'll define the network.\n",
        "\n",
        "<img src=\"assets/network_diagram.png\" width=40%>\n",
        "\n",
        "The layers are as follows:\n",
        "1. An [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) that converts our word tokens (integers) into embeddings of a specific size.\n",
        "2. An [LSTM layer](https://pytorch.org/docs/stable/nn.html#lstm) defined by a hidden_state size and number of layers\n",
        "3. A fully-connected output layer that maps the LSTM layer outputs to a desired output_size\n",
        "4. A sigmoid activation layer which turns all outputs into a value 0-1; return **only the last sigmoid output** as the output of this network.\n",
        "\n",
        "### The Embedding Layer\n",
        "\n",
        "We need to add an [embedding layer](https://pytorch.org/docs/stable/nn.html#embedding) because there are 16500+ words in our vocabulary. It is massively inefficient to one-hot encode that many classes. So, instead of one-hot encoding, we can have an embedding layer and use that layer as a lookup table. \n",
        "\n",
        "\n",
        "### The LSTM Layer(s)\n",
        "\n",
        "We'll create an [LSTM](https://pytorch.org/docs/stable/nn.html#lstm) to use in our recurrent network, which takes in an input_size, a hidden_dim, a number of layers, a dropout probability (for dropout between multiple layers), and a batch_first parameter.\n",
        "\n",
        "Most of the time, the network will have better performance with more layers; between 2-3. Adding more layers allows the network to learn really complex relationships.\n",
        "\n",
        "Note: `init_hidden` should initialize the hidden and cell state of an lstm layer to all zeros, and move those state to GPU, if available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is7L_MLj2hmu",
        "outputId": "5a521b3b-5506-4446-daae-a4f0234ae42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, training on CPU.\n"
          ]
        }
      ],
      "source": [
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if train_on_gpu else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "V15v4KZ-G1Rd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f9ffd8d4-f195-47ba-98d1-cfe43abbb003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM model function."
      ],
      "metadata": {
        "id": "ICm4YUwk1Fow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vA5L0iJc2hmu"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentRNN, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert the given LSTM into a Bi-LSTM implementation, we need to make the following changes: \n",
        "\n",
        "*   Replace the `nn.LSTM` layer with nn.LSTM layer with `bidirectional=True` parameter to create a Bi-LSTM layer.\n",
        "*   Double the size of the hidden layer, as a Bi-LSTM has two sets of hidden states, one for each direction.\n",
        "*   Concatenate the output of the forward and backward LSTM layers before passing it through the final linear layer.\n",
        "\n",
        "Note: The `train_on_gpu` variable used in the `init_hidden` function should be defined and set to True if you want to train the model on a GPU.\n"
      ],
      "metadata": {
        "id": "NT_x6Mry87Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentBiLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The Bi-LSTM model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentBiLSTM, self).__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and Bi-LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True, bidirectional=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs and concatenate the outputs of the forward and backward LSTM layers\n",
        "        lstm_out = lstm_out.view(batch_size, -1, self.hidden_dim*2)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create four new tensors with sizes n_layers*2 x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of Bi-LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers*2, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden\n"
      ],
      "metadata": {
        "id": "BpUmIFtF86f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHZrZ5rO2hmv"
      },
      "source": [
        "### Instantiate the network\n",
        "Here, we'll instantiate the network. First up, defining the hyperparameters.\n",
        "\n",
        "* `vocab_size`: Size of our vocabulary or the range of values for our input, word tokens.\n",
        "* `output_size`: Size of our desired output; the number of class scores we want to output (negative/non-negative).\n",
        "* `embedding_dim`: Number of columns in the embedding lookup table; size of our embeddings.\n",
        "* `hidden_dim`: Number of units in the hidden layers of our LSTM cells. Usually larger is better performance wise. Common values are 128, 256, 512, etc.\n",
        "* `n_layers`: Number of LSTM layers in the network. Typically between 1-3."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating the LSTM network"
      ],
      "metadata": {
        "id": "xpYLgCUH-Dev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psg05q0o2hmv",
        "outputId": "06ea1fdb-f6b3-4d10-e357-300a8c9f044b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(16728, 200)\n",
            "  (lstm): LSTM(200, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding + our word tokens\n",
        "output_size = 1\n",
        "embedding_dim = 200\n",
        "hidden_dim = 128\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instantiating the Bi-LSTM network"
      ],
      "metadata": {
        "id": "AHlcOPib-J7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(vocab_to_int) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "model1 = SentimentBiLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(model1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwXVlmOo-Lhp",
        "outputId": "12314792-9218-414f-b197-1b2bf2c9c9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentBiLSTM(\n",
            "  (embedding): Embedding(16728, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjjnqH8F2hmv"
      },
      "source": [
        "### Training\n",
        "\n",
        "Below is the typical training code. We'll use a cross entropy loss, which is designed to work with a single Sigmoid output. [BCELoss](https://pytorch.org/docs/stable/nn.html#bceloss), or **Binary Cross Entropy Loss**, applies cross entropy loss to a single value between 0 and 1. We also have some data and training hyparameters:\n",
        "\n",
        "* `lr`: Learning rate for our optimizer.\n",
        "* `epochs`: Number of times to iterate through the training dataset.\n",
        "* `clip`: The maximum gradient value to clip at (to prevent exploding gradients)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u5HP5zIM2hmw"
      },
      "outputs": [],
      "source": [
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM model"
      ],
      "metadata": {
        "id": "V5tfGAaAiRyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training params\n",
        "\n",
        "epochs = 10 \n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    net.cuda()\n",
        "\n",
        "wandb.watch(net)\n",
        "\n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "                wandb.log({\"Loss\": loss.item()})\n",
        "                \n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ibR2js5iNjr",
        "outputId": "346313bf-61aa-46b6-ce93-96a145702582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10... Step: 100... Loss: 0.496179... Val Loss: 0.490519\n",
            "Epoch: 1/10... Step: 200... Loss: 0.411499... Val Loss: 0.439217\n",
            "Epoch: 2/10... Step: 300... Loss: 0.442250... Val Loss: 0.462703\n",
            "Epoch: 2/10... Step: 400... Loss: 0.264529... Val Loss: 0.426745\n",
            "Epoch: 3/10... Step: 500... Loss: 0.210555... Val Loss: 0.442121\n",
            "Epoch: 3/10... Step: 600... Loss: 0.228627... Val Loss: 0.435570\n",
            "Epoch: 4/10... Step: 700... Loss: 0.206376... Val Loss: 0.572359\n",
            "Epoch: 4/10... Step: 800... Loss: 0.198518... Val Loss: 0.547640\n",
            "Epoch: 5/10... Step: 900... Loss: 0.218531... Val Loss: 0.568808\n",
            "Epoch: 5/10... Step: 1000... Loss: 0.135115... Val Loss: 0.689068\n",
            "Epoch: 5/10... Step: 1100... Loss: 0.145575... Val Loss: 0.689033\n",
            "Epoch: 6/10... Step: 1200... Loss: 0.020200... Val Loss: 0.761484\n",
            "Epoch: 6/10... Step: 1300... Loss: 0.031238... Val Loss: 0.793764\n",
            "Epoch: 7/10... Step: 1400... Loss: 0.031346... Val Loss: 0.886882\n",
            "Epoch: 7/10... Step: 1500... Loss: 0.198747... Val Loss: 0.958474\n",
            "Epoch: 8/10... Step: 1600... Loss: 0.008756... Val Loss: 1.006280\n",
            "Epoch: 8/10... Step: 1700... Loss: 0.028024... Val Loss: 0.848719\n",
            "Epoch: 9/10... Step: 1800... Loss: 0.018292... Val Loss: 1.030350\n",
            "Epoch: 9/10... Step: 1900... Loss: 0.004630... Val Loss: 1.017522\n",
            "Epoch: 9/10... Step: 2000... Loss: 0.031285... Val Loss: 0.965890\n",
            "Epoch: 10/10... Step: 2100... Loss: 0.101348... Val Loss: 1.070854\n",
            "Epoch: 10/10... Step: 2200... Loss: 0.003801... Val Loss: 1.002956\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-LSTM model"
      ],
      "metadata": {
        "id": "ZALg8FyaiB6R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8_HyDVt2hmw",
        "outputId": "338e0178-ea91-4873-9e0a-260c0f7a44ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/10... Step: 100... Loss: 0.691855... Val Loss: 0.680554\n",
            "Epoch: 1/10... Step: 200... Loss: 0.689520... Val Loss: 0.680802\n",
            "Epoch: 2/10... Step: 300... Loss: 0.695387... Val Loss: 0.681075\n",
            "Epoch: 2/10... Step: 400... Loss: 0.700422... Val Loss: 0.680883\n",
            "Epoch: 3/10... Step: 500... Loss: 0.699294... Val Loss: 0.681196\n",
            "Epoch: 3/10... Step: 600... Loss: 0.688718... Val Loss: 0.681032\n",
            "Epoch: 4/10... Step: 700... Loss: 0.678630... Val Loss: 0.680809\n",
            "Epoch: 4/10... Step: 800... Loss: 0.685882... Val Loss: 0.680789\n",
            "Epoch: 5/10... Step: 900... Loss: 0.688454... Val Loss: 0.680821\n",
            "Epoch: 5/10... Step: 1000... Loss: 0.683797... Val Loss: 0.680969\n",
            "Epoch: 5/10... Step: 1100... Loss: 0.693311... Val Loss: 0.681127\n",
            "Epoch: 6/10... Step: 1200... Loss: 0.690300... Val Loss: 0.680940\n",
            "Epoch: 6/10... Step: 1300... Loss: 0.686655... Val Loss: 0.680721\n",
            "Epoch: 7/10... Step: 1400... Loss: 0.680035... Val Loss: 0.680409\n",
            "Epoch: 7/10... Step: 1500... Loss: 0.690771... Val Loss: 0.680338\n",
            "Epoch: 8/10... Step: 1600... Loss: 0.693805... Val Loss: 0.681038\n",
            "Epoch: 8/10... Step: 1700... Loss: 0.690941... Val Loss: 0.680620\n",
            "Epoch: 9/10... Step: 1800... Loss: 0.680695... Val Loss: 0.680819\n",
            "Epoch: 9/10... Step: 1900... Loss: 0.697662... Val Loss: 0.680819\n",
            "Epoch: 9/10... Step: 2000... Loss: 0.688026... Val Loss: 0.680475\n",
            "Epoch: 10/10... Step: 2100... Loss: 0.680301... Val Loss: 0.680708\n",
            "Epoch: 10/10... Step: 2200... Loss: 0.674370... Val Loss: 0.680795\n"
          ]
        }
      ],
      "source": [
        "# training params\n",
        "\n",
        "epochs = 10 \n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "if(train_on_gpu):\n",
        "    model1.cuda()\n",
        "\n",
        "model1.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    # initialize hidden state\n",
        "    h = model1.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "\n",
        "        if(train_on_gpu):\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        model1.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = model1(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model1.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = model1.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            model1.eval()\n",
        "            for inputs, labels in valid_loader:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                if(train_on_gpu):\n",
        "                    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                output, val_h = model1(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "                wandb.log({\"BI_LSTM_Loss\": loss.item()})\n",
        "\n",
        "            model1.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9VAhGkM2hmw"
      },
      "source": [
        "### Testing\n",
        "\n",
        "We'll see how our trained model performs on all of our defined test_data, above. We'll calculate the average loss and accuracy over the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM model accuracy computation."
      ],
      "metadata": {
        "id": "TSQ9W7FbiyF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    wandb.log({'test_loss':test_loss.item()})\n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    acc = 100.0 * num_correct/len(test_loader.dataset)\n",
        "    wandb.log({\"Testing Accuracy\": acc.item()})\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))\n"
      ],
      "metadata": {
        "id": "u9TfXF5Dixeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c466f670-9b0a-4351-ded6-23c9babdbd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 15.693\n",
            "Test accuracy: 0.733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-LSTM model accuracy computation."
      ],
      "metadata": {
        "id": "_6_3JX1YintB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVvovM9j2hmw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97ba8c0-db2a-4130-e943-6e55ea41ca34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.677\n",
            "Test accuracy: 0.726\n"
          ]
        }
      ],
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = model1.init_hidden(batch_size)\n",
        "\n",
        "model1.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    # get predicted outputs\n",
        "    output, h = model1(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    wandb.log({'BI_LSTM_Test_loss':test_loss.item()})\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "    wandb.log({\"BI_LSTM_Testing Accuracy\": acc.item()})\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUdRjPGO2hmx"
      },
      "source": [
        "---\n",
        "## Creating a predict function\n",
        "We'll write a predict function that takes in a trained net, a plain text_review, and a sequence length, and prints out a custom statement for a non-negative or negative review."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sgRusXjT2hmx"
      },
      "outputs": [],
      "source": [
        "# negative test review\n",
        "test_review = \"@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6gV6YL-2hmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f62d6b8-95f4-4113-fe9e-2a4e60a9f132"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5, 22, 11, 367, 5, 126, 11, 8, 10, 85, 335, 21, 922, 93, 194, 1550, 44, 3, 34, 125, 11, 2888]]\n"
          ]
        }
      ],
      "source": [
        "def tokenize_review(test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    # get rid of punctuation\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    # splitting by spaces\n",
        "    test_words = test_text.split()\n",
        "    \n",
        "    # get rid of web address, twitter id, and digit\n",
        "    new_text = []\n",
        "    for word in test_words:\n",
        "        if (word[0] != '@') & ('http' not in word) & (~word.isdigit()):\n",
        "            new_text.append(word)\n",
        "\n",
        "    # tokens\n",
        "    test_ints = []\n",
        "    test_ints.append([vocab_to_int[word] for word in new_text])\n",
        "\n",
        "    return test_ints\n",
        "\n",
        "# test code and generate tokenized review\n",
        "test_ints = tokenize_review(test_review)\n",
        "print(test_ints)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUJYN5Sc2hmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dd09da6-7955-431b-a2dd-87037b45f6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[   0    0    0    0    0    0    0    0    5   22   11  367    5  126\n",
            "    11    8   10   85  335   21  922   93  194 1550   44    3   34  125\n",
            "    11 2888]]\n"
          ]
        }
      ],
      "source": [
        "# test sequence padding\n",
        "seq_length=30\n",
        "features = pad_features(test_ints, seq_length)\n",
        "\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khc3HxWp2hmy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36a663ce-1c39-4028-cd00-9ae7c83b07af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 30])\n"
          ]
        }
      ],
      "source": [
        "# test conversion to tensor and pass into your model\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "bJai4s-E2hmy"
      },
      "outputs": [],
      "source": [
        "def predict(net, test_review, sequence_length=30):\n",
        "    \n",
        "    net.eval()\n",
        "    \n",
        "    # tokenize review\n",
        "    test_ints = tokenize_review(test_review)\n",
        "    \n",
        "    # pad tokenized sequence\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features(test_ints, seq_length)\n",
        "    \n",
        "    # convert to tensor to pass into your model\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "    \n",
        "    batch_size = feature_tensor.size(0)\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "    \n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "    \n",
        "    # get the output from the model\n",
        "    output, h = net(feature_tensor, h)\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze()) \n",
        "    # printing output value, before rounding\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "    \n",
        "    # print custom response\n",
        "    if(pred.item()==1):\n",
        "        print(\"Non-negative review detected.\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWjMANQK2hmz"
      },
      "outputs": [],
      "source": [
        "seq_length = 30 # good to use the length that was trained on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqbChW8K2hmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b62fdba6-714c-4cf6-e193-d051bec7fb88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.000000\n",
            "Negative review detected.\n"
          ]
        }
      ],
      "source": [
        "# call function on negative review\n",
        "test_review_neg = \"@AmericanAir you have my money, you change my flight, and don't answer your phones! Any other suggestions so I can make my commitment??\"\n",
        "predict(net, test_review_neg, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVi60SbH2hm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fb0ceb-638b-4eed-c3fe-c035ec0c9a5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.000000\n",
            "Negative review detected.\n"
          ]
        }
      ],
      "source": [
        "# call function on positive review\n",
        "test_review_pos = \"@AmericanAir thank you we got on a different flight to Chicago.\"\n",
        "predict(net, test_review_pos, seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ns3-5DfG2hm1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22bf9750-13d8-4cba-93a7-758e6db5c957"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction value, pre-rounding: 0.000000\n",
            "Negative review detected.\n"
          ]
        }
      ],
      "source": [
        "# call function on neutral review\n",
        "test_review_neu = \"@AmericanAir i need someone to help me out\"\n",
        "predict(net, test_review_neu, seq_length)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}